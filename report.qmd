---
format: html
editor: visual
---

```{r, eval = F}
# This code chunk contains code to install all of the dependencies
# necessary to compile and run your report, using if-statements to
# reduce install time for unnecessary code.
# It should be set to eval = F by default, so you aren't installing
# software on someone's computer without their consent.

# This works for packages that are on CRAN
if (!"dplyr" %in% installed.packages()) {
  install.packages("dplyr")
}
if (!"remotes" %in% installed.packages()) {
  install.packages("remotes")
}

# This is how to do it for a package that's only on github
#if (!"emo" %in% installed.packages()) {
 # remotes::install_github("hadley/emo")

```

## Introduction

This dataset contains information about the fiction bestseller list of **The New York Times** between the years **1931 to 2020**. This dataset includes the title, author(s), publication date, rank, and other information for every work recorded since the list's founding in 1931.

Every row in the dataset represents a single "entry"---a single slot for a particular week---on the list. There are usually ten or fifteen works listed each week. But the number of bestsellers the Times features in a given week varies, so there may be 3, 6, 7, 8, or 16.

It was collected from the **Tidy Tuesday Archive**. The source link is- https://github.com/rfordatascience/tidytuesday/blob/master/data/2022/2022-05-10/readme.md#nyt_titlestsv

There are 8 variables in nyt_titles and 6 variables in nyt_full. Here is a data dictionary showing each variable, the type of variable, units, and range of values that are possible:

nyt_full.tsv:

-    year - the year of appearance 

-   week - the weekly issue of the bestseller list 

-   rank - the book's rank on the list for that week 

-   title_id - a unique ID mapping titles to the nyt_titles spreadsheet 

-   title - title of the novel, as reported by the New York Times 

-   author - author of the novel, as reported by the New York Times

nyt_titles.tsv:

-   id - an arbitrary unique id for the novel

-    title - the title of the novel, as reported by the New York Times

-    author - the author of the novel, as reported by the New York Times 

-   year - the first year that the novel appears on the bestseller list. 

-   total_weeks - the total number of weeks the title was on the list 

-   first_week - the first week that the novel appears on the bestseller list 

-   debut_rank - the book's bestseller rank in the week of its first appearance

-   best_rank - the highest rank achieved by the title while on the list

The above dataset will be used to explore different topics that will help book lovers to find out which authors have occasionally stayed on top of the best sellers list based on the total number of weeks or how many times they appeared on the list. We are considering data from 2000 to 2020, and we would like to look into the relationship between the debut rank and the total number of weeks a book has been on the list. In the meantime, we want to show the distribution of variables (year, total_week,debut_rank) in terms of bestsellers and a shiny app to find books by their author name. 

We have two variables in our dataset which are the debut rank and best rank , but there were some anomalies where the best rank for some books was a value greater than the debut rank , maybe this was due to some incorrect data entries so we removed those records as a data cleaning process.

**Objectives of this whole analysis:**

-   Average Total Weeks on Bestseller List per Year

-   Distribution of variables (total_weeks, debut_rank)

-   Top 10 books and authors in the bestseller list for the most number of weeks

-   Highest number of weeks a book appeared in the list in each year 

-   Relationship between the Debut Rank of a book and the Total Number of weeks in the list

-   Top 10 authors in the list based on the number of appearances over the years

-   Debut rank distribution for the top 10 authors in the list based on the number of appearances over the years

-   Best rank distribution for the top 10 authors in the list based on the number of appearances over the years

-   Checking significant relationships of best_rank variable with total_weeks and debut_rank 

## Methods

> As there are 2 datasets, nyt_titles and nyt_full we combined the 2 datasets and obtained a single dataframe. We used the `left_join` function from [@dplyr-package] `dplyr` package and combined 2 datasets using the title_id. As we are only interested in bestseller books from 2000 to 2020, we filtered the records from 2000 to 2020 from the combined dataset using the `filter` function.

```{r}
#| echo: false
# Get the Data

tuesdata <- tidytuesdayR::tt_load('2022-05-10')
tuesdata <- tidytuesdayR::tt_load(2022, week = 19)

nyt_titles <- tuesdata$nyt_titles

# Or read in the data manually

nyt_titles <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-10/nyt_titles.tsv')
nyt_full <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-10/nyt_full.tsv')

library(dplyr)

#Combine the two dataframes
result <- nyt_full %>%
  left_join(select(nyt_titles,-year,-author,-title), by = c("title_id" = "id"))

# Filter rows with years from 2000 to 2020
filtered_data <- result %>%
  filter(year >= 2000&year<=2020)

```

> We created a new variable and added a new column called rank_difference by subtracting the best_rank from debut_rank. This is because there were some records where there were some errors in these two columns, therefore we only kept the rows where the best rank was a value less than or equal to the debut rank. We used the `filter` function from [@dplyr-package] `dplyr` package to do this. We used this dataset (filtered_final) to do some of our analysis. Since we wanted to check the correlation and fit a regression model we used this filtered dataset to explore our objectives.

```{r}
#| echo: false

#keeping only the records where the best rank is less than or equal to debut rank
filtered_final <- filtered_data %>%
  filter(best_rank <=debut_rank)

#creating the new column rank_difference
filtered_final <- filtered_final %>%
  mutate(rank_difference = debut_rank - best_rank)

```

>There were many records for one book title and due to that we were not able to obtain meaningful results and clear visual representations. Another topic we wanted to explore was comparing the variables best_rank, debut_rank and total_weeks. But these variables do not depend on the week the book appeared on the list, it only depends on the title id of the book. Therefore to get a more clear idea we filtered the dataset by keeping only the distinct title ids and carried out the rest of the analysis using this dataset.We used the `filter` function from [@dplyr-package] `dplyr` package to do this.Our filtered_final dataset contains 13164 observations and 11 variables. And the dataset we obtained after getting only the unique title id’s had 2276 observations and 11 variables.

```{r}
#| echo: false

# Keep only one row per book
final_data <- filtered_final %>%
  distinct(title_id, .keep_all=TRUE)

```

## Topic of Exploration

Here, you want to introduce the first topic you want to explore with your (newly cleaned up) data. Code to process data should be contained in chunks above this point, and those chunks should *not* be included in the report.

You can add options to executable code like this

```{r}
#| echo: false
2 * 2
```

The `echo: false` option disables the printing of code (only output is displayed).

If you generate a figure, it should have a caption. Here's a demonstration of how to do that:

```{r iris-plot}
#| label: fig-iris
#| fig-width: 8
#| fig-height: 4 # Change the figure dimensions using fig-width/height
#| out-width: 80% # This changes the size of the figure as rendered in the text. 
#| fig-cap: "This figure shows the relationship between sepal width and petal width in irises. I've used geom_jitter to combat overplotting, as the data are measured in relatively consistent increments. The figure is drawn with `ggplot2` [@ggplot2-package]."
#| echo: false


data(iris)
library(ggplot2)
ggplot(iris, aes(x = Sepal.Width, y = Petal.Width, color = Species)) + 
  geom_jitter() + 
  xlab("Sepal Width (cm)") + ylab("Petal Width (cm)") + 
  ggtitle("Sepal and Petal Dimensions")
```

Then, you can reference @fig-iris in the text and the appropriate cross-reference will be generated.

You can find additional information about formatting figures generated from code in the [quarto documentation](https://quarto.org/docs/authoring/figures.html#computations).

## Additional Exploration topic

Add another topic here... as many as you desire, really. Make sure to include a transition between the two sections that connects the two with some sort of logical train of thought.

## Conclusion

Here, you want to summarize the main points of what you've learned from this investigation, in paragraph form.

## Tips

(delete this section from your report!)

Almost anything you might want to know about how to format output in quarto can be found [here](https://quarto.org/docs/authoring/markdown-basics.html). Feel free to email/come to office hours to figure out how to do XYZ - part of the goal of making you write this report is that I want you to know how to write e.g. a journal paper in Quarto as well, so now's the time to experiment.

If you want to know what the wordcount of your report is, you can run the following command in your terminal:

```         
pandoc --lua-filter wordcount.lua report.qmd
```

Notice that I have not pushed `_output/report.html` or the `_output/report_files/` folder to github - this is intentional. I have actually set `_output` to not show up in git, to encourage you all to NOT push the rendered files to github and to instead work from the markdown files directly.

You may find it cleaner to create a figure subdirectory and store any figures that aren't created by R/Python in that folder. I encourage you to organize this repository in a sensible way.
